{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-01]** 必要なモジュールをインポートして、乱数のシードを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yohei/.pyenv/versions/anaconda3-5.0.0/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle\n",
    "\n",
    "np.random.seed(20160703)\n",
    "tf.set_random_seed(20160703)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-02]** データファイル「ORENIST.data」から画像とラベルのデータを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ORENIST.data', 'rb') as file:\n",
    "    images, labels = pickle.load(file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-03]** フィルターの情報を格納した多次元リストを作る関数を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter():\n",
    "    filter0 = np.array(\n",
    "            [[ 2, 1, 0,-1,-2],\n",
    "             [ 3, 2, 0,-2,-3],\n",
    "             [ 4, 3, 0,-3,-4],\n",
    "             [ 3, 2, 0,-2,-3],\n",
    "             [ 2, 1, 0,-1,-2]]) / 23.0\n",
    "    filter1 = np.array(\n",
    "            [[ 2, 3, 4, 3, 2],\n",
    "             [ 1, 2, 3, 2, 1],\n",
    "             [ 0, 0, 0, 0, 0],\n",
    "             [-1,-2,-3,-2,-1],\n",
    "             [-2,-3,-4,-3,-2]]) / 23.0\n",
    "    \n",
    "    filter_array = np.zeros([5,5,1,2]) # FH, FW, C, FN\n",
    "    filter_array[:,:,0,0] = filter0\n",
    "    filter_array[:,:,0,1] = filter1\n",
    "\n",
    "    return tf.constant(filter_array, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-04]** 画像データにフィルターとプーリング層を適用する計算式を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) # N, H, W, C\n",
    "\n",
    "W_conv = edge_filter()\n",
    "h_conv = tf.abs(tf.nn.conv2d(x_image, W_conv,\n",
    "                             strides=[1,1,1,1], padding='SAME'))\n",
    "h_conv_cutoff = tf.nn.relu(h_conv-0.2)\n",
    "\n",
    "h_pool =tf.nn.max_pool(h_conv_cutoff, ksize=[1,2,2,1],\n",
    "                       strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-05]** プーリング層からの出力を全結合層とソフトマックス関数からなる「拡張された出力層」に入力する計算式を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool_flat = tf.reshape(h_pool, [-1, 392])  # 14*14*2 = 392 の実数値として全結合層のノードに入力\n",
    "\n",
    "num_units1 = 392\n",
    "num_units2 = 2\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))\n",
    "b2 = tf.Variable(tf.zeros([num_units2]))\n",
    "hidden2 = tf.nn.tanh(tf.matmul(h_pool_flat, w2) + b2)  # 特徴をバイナリ化 \n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units2, 3]))\n",
    "b0 = tf.Variable(tf.zeros([3]))\n",
    "p = tf.nn.softmax(tf.matmul(hidden2, w0) + b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-06]** 誤差関数 loss、トレーニングアルゴリズム train_step、正解率 accuracy を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, 3])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-07]** セッションを用意して、Variable を初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-08]** パラメーターの最適化を200回繰り返します。\n",
    "\n",
    "約100回の繰り返しで、100%の正解率を達成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, Loss: 97.706993, Accuracy: 0.788889\n",
      "Step: 20, Loss: 96.378815, Accuracy: 0.822222\n",
      "Step: 30, Loss: 94.918198, Accuracy: 0.833333\n",
      "Step: 40, Loss: 93.346489, Accuracy: 0.911111\n",
      "Step: 50, Loss: 91.696594, Accuracy: 0.922222\n",
      "Step: 60, Loss: 89.997673, Accuracy: 0.933333\n",
      "Step: 70, Loss: 88.272461, Accuracy: 0.966667\n",
      "Step: 80, Loss: 86.562065, Accuracy: 0.988889\n",
      "Step: 90, Loss: 84.892662, Accuracy: 1.000000\n",
      "Step: 100, Loss: 83.274239, Accuracy: 1.000000\n",
      "Step: 110, Loss: 81.711754, Accuracy: 1.000000\n",
      "Step: 120, Loss: 80.205574, Accuracy: 1.000000\n",
      "Step: 130, Loss: 78.751511, Accuracy: 1.000000\n",
      "Step: 140, Loss: 77.344208, Accuracy: 1.000000\n",
      "Step: 150, Loss: 75.978905, Accuracy: 1.000000\n",
      "Step: 160, Loss: 74.651871, Accuracy: 1.000000\n",
      "Step: 170, Loss: 73.360237, Accuracy: 1.000000\n",
      "Step: 180, Loss: 72.101730, Accuracy: 1.000000\n",
      "Step: 190, Loss: 70.874496, Accuracy: 1.000000\n",
      "Step: 200, Loss: 69.676971, Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(200):\n",
    "    i += 1\n",
    "    sess.run(train_step, feed_dict={x:images, t:labels})\n",
    "    if i % 10 == 0:\n",
    "        loss_val, acc_val = sess.run(\n",
    "            [loss, accuracy], feed_dict={x:images, t:labels})\n",
    "        print ('Step: %d, Loss: %f, Accuracy: %f'\n",
    "               % (i, loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OCE-09]** それぞれのデータの特徴変数 (z1, z2) を散布図に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x181cbfcc88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181cc19748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden2_vals = sess.run(hidden2, feed_dict={x:images})\n",
    "\n",
    "z1_vals = [[],[],[]]\n",
    "z2_vals = [[],[],[]]\n",
    "\n",
    "for hidden2_val, label in zip(hidden2_vals, labels):\n",
    "    label_num = np.argmax(label)\n",
    "    z1_vals[label_num].append(hidden2_val[0])\n",
    "    z2_vals[label_num].append(hidden2_val[1])\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "subplot = fig.add_subplot(1,1,1)\n",
    "subplot.scatter(z1_vals[0], z2_vals[0], s=200, marker='|')\n",
    "subplot.scatter(z1_vals[1], z2_vals[1], s=200, marker='_')\n",
    "subplot.scatter(z1_vals[2], z2_vals[2], s=200, marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Lambda, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(shape, dtype=None):\n",
    "#def weight_init():\n",
    "    filter0 = np.array(\n",
    "            [[ 2, 1, 0,-1,-2],\n",
    "             [ 3, 2, 0,-2,-3],\n",
    "             [ 4, 3, 0,-3,-4],\n",
    "             [ 3, 2, 0,-2,-3],\n",
    "             [ 2, 1, 0,-1,-2]]) / 23.0\n",
    "    filter1 = np.array(\n",
    "            [[ 2, 3, 4, 3, 2],\n",
    "             [ 1, 2, 3, 2, 1],\n",
    "             [ 0, 0, 0, 0, 0],\n",
    "             [-1,-2,-3,-2,-1],\n",
    "             [-2,-3,-4,-3,-2]]) / 23.0\n",
    "    \n",
    "    filter_array = np.zeros([5,5,1,2])\n",
    "    filter_array[:,:,0,0] = filter0\n",
    "    filter_array[:,:,0,1] = filter1\n",
    "\n",
    "    print(\"filter shape: \",  filter_array.shape)\n",
    "    return filter_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter shape:  (5, 5, 1, 2)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 2)         50        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 28, 28, 2)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 786       \n",
      "_________________________________________________________________\n",
      "hidden (Activation)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 845\n",
      "Trainable params: 795\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(filters=2, kernel_size=5,\n",
    "                 padding=\"same\",\n",
    "                 data_format=\"channels_last\",\n",
    "                 use_bias=False,\n",
    "                 input_shape=(28, 28, 1),\n",
    "                kernel_initializer=weight_init,\n",
    "                trainable=False\n",
    "                ))\n",
    "model.add(Lambda(lambda x: x - 0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       padding=\"same\", \n",
    "                       data_format=\"channels_last\"))\n",
    "model.add(Flatten())  #  入力を平滑化する．バッチサイズに影響されない．\n",
    "model.add(Dense(units=2))\n",
    "model.add(Activation('tanh', name='hidden'))\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(images)\n",
    "x = x.reshape([-1,28,28,1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.1255 - acc: 0.5222\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 0s 148us/step - loss: 1.1190 - acc: 0.5556\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 0s 178us/step - loss: 1.1125 - acc: 0.5444\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 0s 181us/step - loss: 1.1061 - acc: 0.5556\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 0s 187us/step - loss: 1.0997 - acc: 0.5667\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 0s 225us/step - loss: 1.0934 - acc: 0.5667\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 1.0871 - acc: 0.5667\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 0s 187us/step - loss: 1.0810 - acc: 0.6111\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 0s 317us/step - loss: 1.0748 - acc: 0.6333\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 0s 208us/step - loss: 1.0687 - acc: 0.6333\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 0s 207us/step - loss: 1.0627 - acc: 0.6333\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 0s 184us/step - loss: 1.0567 - acc: 0.6444\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 0s 192us/step - loss: 1.0508 - acc: 0.6333\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 0s 236us/step - loss: 1.0450 - acc: 0.6333\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 1.0393 - acc: 0.6333\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 0s 223us/step - loss: 1.0337 - acc: 0.6333\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 0s 184us/step - loss: 1.0281 - acc: 0.6333\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 0s 164us/step - loss: 1.0227 - acc: 0.6556\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 0s 152us/step - loss: 1.0173 - acc: 0.6667\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 0s 225us/step - loss: 1.0120 - acc: 0.7222\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 0s 181us/step - loss: 1.0068 - acc: 0.7556\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 0s 179us/step - loss: 1.0016 - acc: 0.8000\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 0s 242us/step - loss: 0.9966 - acc: 0.8000\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 0s 170us/step - loss: 0.9916 - acc: 0.8222\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 0s 166us/step - loss: 0.9866 - acc: 0.8444\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 0s 212us/step - loss: 0.9817 - acc: 0.8778\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 0s 160us/step - loss: 0.9769 - acc: 0.8778\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.9721 - acc: 0.8778\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 0s 280us/step - loss: 0.9674 - acc: 0.8778\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.9628 - acc: 0.8778\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 0s 159us/step - loss: 0.9582 - acc: 0.8889\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 0s 229us/step - loss: 0.9536 - acc: 0.8889\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 0s 176us/step - loss: 0.9491 - acc: 0.8778\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.9446 - acc: 0.8667\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 0s 264us/step - loss: 0.9401 - acc: 0.8667\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.9357 - acc: 0.8667\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 0s 159us/step - loss: 0.9313 - acc: 0.8667\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 0s 154us/step - loss: 0.9270 - acc: 0.8667\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 0s 233us/step - loss: 0.9227 - acc: 0.8667\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 0s 168us/step - loss: 0.9184 - acc: 0.8667\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 0s 149us/step - loss: 0.9142 - acc: 0.8444\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 0s 162us/step - loss: 0.9101 - acc: 0.8333\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 0s 221us/step - loss: 0.9060 - acc: 0.8222\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.9019 - acc: 0.8222\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.8978 - acc: 0.8222\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.8939 - acc: 0.8111\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.8899 - acc: 0.8111\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.8860 - acc: 0.8111\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.8822 - acc: 0.8111\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 0s 171us/step - loss: 0.8783 - acc: 0.8111\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 0s 215us/step - loss: 0.8746 - acc: 0.8111\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.8708 - acc: 0.8111\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 0s 173us/step - loss: 0.8671 - acc: 0.8111\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 0s 160us/step - loss: 0.8635 - acc: 0.8111\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 0s 249us/step - loss: 0.8599 - acc: 0.8111\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.8563 - acc: 0.8111\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 0s 167us/step - loss: 0.8528 - acc: 0.8111\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 0s 175us/step - loss: 0.8493 - acc: 0.8111\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 0s 218us/step - loss: 0.8458 - acc: 0.8111\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.8424 - acc: 0.8111\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 0s 167us/step - loss: 0.8390 - acc: 0.8111\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 0s 321us/step - loss: 0.8356 - acc: 0.8000\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.8323 - acc: 0.8000\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 0s 175us/step - loss: 0.8290 - acc: 0.8000\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.8257 - acc: 0.8000\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.8224 - acc: 0.8000\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 0s 197us/step - loss: 0.8192 - acc: 0.8000\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.8160 - acc: 0.8000\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.8128 - acc: 0.8000\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.8097 - acc: 0.8000\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 0s 173us/step - loss: 0.8065 - acc: 0.8000\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 0s 157us/step - loss: 0.8034 - acc: 0.8000\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.8003 - acc: 0.8000\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 0s 152us/step - loss: 0.7972 - acc: 0.8000\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 0s 165us/step - loss: 0.7942 - acc: 0.8111\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 0s 155us/step - loss: 0.7911 - acc: 0.8222\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 0s 215us/step - loss: 0.7881 - acc: 0.8222\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 0s 168us/step - loss: 0.7851 - acc: 0.8444\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 0s 162us/step - loss: 0.7822 - acc: 0.8556\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 0s 156us/step - loss: 0.7792 - acc: 0.8556\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 0s 156us/step - loss: 0.7763 - acc: 0.8667\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.7734 - acc: 0.8778\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 0s 174us/step - loss: 0.7705 - acc: 0.8778\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.7676 - acc: 0.9000\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 0s 221us/step - loss: 0.7647 - acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "90/90 [==============================] - 0s 151us/step - loss: 0.7618 - acc: 0.9111\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 0s 158us/step - loss: 0.7590 - acc: 0.9111\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 0s 157us/step - loss: 0.7562 - acc: 0.9222\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.7533 - acc: 0.9222\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.7505 - acc: 0.9333\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 0s 152us/step - loss: 0.7478 - acc: 0.9333\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.7450 - acc: 0.9444\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.7422 - acc: 0.9556\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.7395 - acc: 0.9667\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 0s 230us/step - loss: 0.7367 - acc: 0.9889\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 0s 155us/step - loss: 0.7340 - acc: 0.9889\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 0s 157us/step - loss: 0.7313 - acc: 0.9889\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.7286 - acc: 0.9889\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.7259 - acc: 0.9889\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 0s 203us/step - loss: 0.7232 - acc: 0.9889\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.7206 - acc: 0.9889\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - 0s 175us/step - loss: 0.7179 - acc: 0.9889\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.7153 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.7126 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 0s 196us/step - loss: 0.7100 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.7074 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.7048 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 0s 158us/step - loss: 0.7022 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.6997 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 0s 155us/step - loss: 0.6971 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 0s 158us/step - loss: 0.6946 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.6920 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 0s 153us/step - loss: 0.6895 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 0s 155us/step - loss: 0.6870 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 0s 155us/step - loss: 0.6845 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 0s 177us/step - loss: 0.6820 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 0s 156us/step - loss: 0.6795 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.6771 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 0s 162us/step - loss: 0.6746 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 0s 161us/step - loss: 0.6722 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.6697 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 0s 170us/step - loss: 0.6673 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 0s 170us/step - loss: 0.6649 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 0s 208us/step - loss: 0.6625 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 0s 167us/step - loss: 0.6602 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.6578 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 0s 161us/step - loss: 0.6554 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 0s 179us/step - loss: 0.6531 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 0s 199us/step - loss: 0.6508 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.6485 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.6461 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 0s 177us/step - loss: 0.6439 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 0s 160us/step - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 0s 194us/step - loss: 0.6393 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 0s 223us/step - loss: 0.6370 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.6348 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6326 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.6303 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 0s 161us/step - loss: 0.6281 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.6259 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.6237 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 0s 265us/step - loss: 0.6216 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.6194 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.6172 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6151 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 0s 216us/step - loss: 0.6130 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.6109 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 0s 187us/step - loss: 0.6088 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 0s 218us/step - loss: 0.6067 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.6046 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 0s 235us/step - loss: 0.6025 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 0s 215us/step - loss: 0.6005 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 0s 204us/step - loss: 0.5984 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 0s 227us/step - loss: 0.5964 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 0s 174us/step - loss: 0.5944 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 0s 181us/step - loss: 0.5923 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.5903 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.5884 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 0s 173us/step - loss: 0.5864 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 0s 166us/step - loss: 0.5844 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 0s 178us/step - loss: 0.5825 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 0s 243us/step - loss: 0.5805 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5786 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "90/90 [==============================] - 0s 276us/step - loss: 0.5767 - acc: 1.0000\n",
      "Epoch 165/200\n",
      "90/90 [==============================] - 0s 224us/step - loss: 0.5747 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "90/90 [==============================] - 0s 228us/step - loss: 0.5728 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "90/90 [==============================] - 0s 211us/step - loss: 0.5710 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "90/90 [==============================] - 0s 182us/step - loss: 0.5691 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "90/90 [==============================] - 0s 177us/step - loss: 0.5672 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "90/90 [==============================] - 0s 195us/step - loss: 0.5654 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "90/90 [==============================] - 0s 209us/step - loss: 0.5635 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.5617 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "90/90 [==============================] - 0s 177us/step - loss: 0.5599 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "90/90 [==============================] - 0s 190us/step - loss: 0.5580 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "90/90 [==============================] - 0s 239us/step - loss: 0.5562 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "90/90 [==============================] - 0s 200us/step - loss: 0.5544 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "90/90 [==============================] - 0s 239us/step - loss: 0.5527 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "90/90 [==============================] - 0s 185us/step - loss: 0.5509 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "90/90 [==============================] - 0s 166us/step - loss: 0.5491 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.5474 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "90/90 [==============================] - 0s 183us/step - loss: 0.5456 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.5439 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "90/90 [==============================] - 0s 186us/step - loss: 0.5422 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "90/90 [==============================] - 0s 189us/step - loss: 0.5405 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "90/90 [==============================] - 0s 169us/step - loss: 0.5388 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "90/90 [==============================] - 0s 206us/step - loss: 0.5371 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.5354 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "90/90 [==============================] - 0s 184us/step - loss: 0.5337 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "90/90 [==============================] - 0s 220us/step - loss: 0.5321 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "90/90 [==============================] - 0s 229us/step - loss: 0.5304 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "90/90 [==============================] - 0s 165us/step - loss: 0.5288 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "90/90 [==============================] - 0s 232us/step - loss: 0.5271 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "90/90 [==============================] - 0s 325us/step - loss: 0.5255 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "90/90 [==============================] - 0s 202us/step - loss: 0.5239 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "90/90 [==============================] - 0s 188us/step - loss: 0.5223 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "90/90 [==============================] - 0s 224us/step - loss: 0.5207 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "90/90 [==============================] - 0s 198us/step - loss: 0.5191 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "90/90 [==============================] - 0s 221us/step - loss: 0.5175 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "90/90 [==============================] - 0s 231us/step - loss: 0.5160 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "90/90 [==============================] - 0s 268us/step - loss: 0.5144 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "hist = model.fit(x, labels, batch_size=x.shape[0], epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Activation at 0x181c610940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden/Tanh:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('hidden').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中間層の出力を得るためには新たなModel を作成\n",
    "layer_name = 'hidden'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output) # 入力がinputで出力層は欲しい中間層のTensor\n",
    "intermediate_output = intermediate_layer_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x181dc21c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181dc02da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden2_vals = intermediate_output\n",
    "\n",
    "z1_vals = [[],[],[]]\n",
    "z2_vals = [[],[],[]] \n",
    "\n",
    "for hidden2_val, label in zip(hidden2_vals, labels):\n",
    "    label_num = np.argmax(label)\n",
    "    z1_vals[label_num].append(hidden2_val[0])\n",
    "    z2_vals[label_num].append(hidden2_val[1])\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "subplot = fig.add_subplot(1,1,1)\n",
    "subplot.scatter(z1_vals[0], z2_vals[0], s=200, marker='|')\n",
    "subplot.scatter(z1_vals[1], z2_vals[1], s=200, marker='_')\n",
    "subplot.scatter(z1_vals[2], z2_vals[2], s=200, marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
