{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-01]** 必要なモジュールをインポートして、乱数のシードを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "np.random.seed(20160703)\n",
    "tf.set_random_seed(20160703)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-02]** MNISTのデータセットを用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-03]** フィルターに対応する Variable を用意して、入力データにフィルターとプーリング層を適用する計算式を定義します。\n",
    "\n",
    "保存するときはモデルのパラメータを対応づけるため，変数(Variable)には名前をつけるのが良い．  \n",
    "name=NoneのままだとしてもTFは自動的にuniquな名前をつけてくれるので，リストアするときは全く同じ式を立てれば問題ないが．．．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x110e2ecc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x1a35439710>\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    print(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x110e2ecc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "num_filters = 16\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])  # N,H,W,C\n",
    "\n",
    "# 変数に名前をつける\n",
    "W_conv = tf.Variable(tf.truncated_normal([5,5,1,num_filters],  # FH,FW,C,FN    [filter_height, filter_width, in_channels, out_channels]\n",
    "                                          stddev=0.1), name='W_conv')\n",
    "\"\"\"\n",
    "tf.get_variableは、既に存在すれば取得し(エラー出す?)、なければ変数を作成する関数です。\n",
    "tf.Variableとは違い、変数値ではなく、第一引数に変数の名前を指定することが必須となっています。\n",
    "このとき，initializerにはInitializer that generates~の関数しか使えない．\n",
    "tf.truncated_normal は　initializer引数には使えないので注意\n",
    "おそらく，関数名に ~_initializer()  が付いているのがinitializer引数に使える引数のよう\n",
    "\"\"\"\n",
    "#W_conv = tf.get_variable('W_conv', shape=[5,5,1,num_filters], \n",
    "#                           initializer=tf.truncated_normal_initializer(stddev=0.01))  \n",
    " \n",
    "h_conv = tf.nn.conv2d(x_image, W_conv,\n",
    "                      strides=[1,1,1,1], padding='SAME')\n",
    "h_pool =tf.nn.max_pool(h_conv, ksize=[1,2,2,1],\n",
    "                       strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-04]** プーリング層からの出力を全結合層を経由してソフトマックス関数に入力する計算式を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool_flat = tf.reshape(h_pool, [-1, 14*14*num_filters])\n",
    "\n",
    "num_units1 = 14*14*num_filters\n",
    "num_units2 = 1024\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]), name='w2')\n",
    "b2 = tf.Variable(tf.zeros([num_units2]), name='b2')\n",
    "hidden2 = tf.nn.relu(tf.matmul(h_pool_flat, w2) + b2)\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units2, 10]), name='w0')\n",
    "b0 = tf.Variable(tf.zeros([10]), name='b0')\n",
    "p = tf.nn.softmax(tf.matmul(hidden2, w0) + b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-05]** 誤差関数 loss、トレーニングアルゴリズム train_step、正解率 accuracy を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(p))\n",
    "train_step = tf.train.AdamOptimizer(0.0005).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-06]** セッションを用意して、Variable を初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  # Variableを初期化する　これでVariableが値を持つことになる\n",
    "saver = tf.train.Saver()  # セッション保存用  tf.global_variables_initializer()の実行後でなければならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-07]** パラメーターの最適化を4000回繰り返します。\n",
    "\n",
    "最終的に、テストセットに対して約98%の正解率が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r  tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行しているファイルが格納されているディレクトリのパスを取得したい。\n",
    "\n",
    "https://qiita.com/neko_the_shadow/items/09ff3a423954a2adfe18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yohei/Documents/Study/jupyter_tfbook/Chapter04/hoge'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd + '/hoge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-27c94ab83c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m__file__\u001b[0m  \u001b[0;31m# これはipnbだと使えないようだ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "__file__  # これはipnbだと使えないようだ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('.'),\n",
       " PosixPath('/Users/yohei/Documents/Study/jupyter_tfbook/Chapter04'),\n",
       " PosixPath('/Users/yohei/Documents/Study/jupyter_tfbook'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pathlibを使って柔軟にファイル操作を行う\n",
    "import pathlib\n",
    "\n",
    "#  このスクリプトファイルがあるディレクトリの絶対パスを取得\n",
    "\n",
    "root = pathlib.Path('.')  # 今のスクリプトファイルのPathオブジェクトを生成\n",
    "abs_root = root.resolve()  # そのパスを絶対パスに変換\n",
    "parent = abs_root.parent  # parent属性でこのスクリプトがあるディレクトリまでの絶対パスを作成\n",
    "root, abs_root, parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yohei/Documents/Study/jupyter_tfbook/Chapter04/hoge'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(abs_root / 'hoge')  # / でファイルをつなぐことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd + '/hoge' == str(abs_root / 'hoge') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, Loss: 2331.055176, Accuracy: 0.930300\n",
      "Step: 200, Loss: 1905.531738, Accuracy: 0.941500\n",
      "Step: 300, Loss: 1501.040894, Accuracy: 0.953800\n",
      "Step: 400, Loss: 1300.982910, Accuracy: 0.960900\n",
      "Step: 500, Loss: 1098.262695, Accuracy: 0.965800\n",
      "Step: 600, Loss: 1033.074951, Accuracy: 0.969500\n",
      "Step: 700, Loss: 1164.076050, Accuracy: 0.963200\n",
      "Step: 800, Loss: 972.950317, Accuracy: 0.969500\n",
      "Step: 900, Loss: 861.703735, Accuracy: 0.973500\n",
      "Step: 1000, Loss: 941.364685, Accuracy: 0.970800\n",
      "Step: 1100, Loss: 809.683899, Accuracy: 0.974800\n",
      "Step: 1200, Loss: 713.957947, Accuracy: 0.977700\n",
      "Step: 1300, Loss: 846.246338, Accuracy: 0.974200\n",
      "Step: 1400, Loss: 721.964355, Accuracy: 0.978400\n",
      "Step: 1500, Loss: 714.643005, Accuracy: 0.978300\n",
      "Step: 1600, Loss: 779.952637, Accuracy: 0.976800\n",
      "Step: 1700, Loss: 692.447815, Accuracy: 0.978300\n",
      "Step: 1800, Loss: 801.884949, Accuracy: 0.974400\n",
      "Step: 1900, Loss: 713.758789, Accuracy: 0.978900\n",
      "Step: 2000, Loss: 701.541626, Accuracy: 0.980100\n",
      "Step: 2100, Loss: 650.176392, Accuracy: 0.979600\n",
      "Step: 2200, Loss: 711.871033, Accuracy: 0.978000\n",
      "Step: 2300, Loss: 677.084839, Accuracy: 0.979200\n",
      "Step: 2400, Loss: 701.301880, Accuracy: 0.980000\n",
      "Step: 2500, Loss: 650.227905, Accuracy: 0.980200\n",
      "Step: 2600, Loss: 735.811279, Accuracy: 0.977400\n",
      "Step: 2700, Loss: 632.119385, Accuracy: 0.980400\n",
      "Step: 2800, Loss: 717.985718, Accuracy: 0.978300\n",
      "Step: 2900, Loss: 687.880249, Accuracy: 0.980800\n",
      "Step: 3000, Loss: 729.590637, Accuracy: 0.979700\n",
      "Step: 3100, Loss: 698.534119, Accuracy: 0.980100\n",
      "Step: 3200, Loss: 737.139587, Accuracy: 0.980200\n",
      "Step: 3300, Loss: 711.927185, Accuracy: 0.979800\n",
      "Step: 3400, Loss: 663.207764, Accuracy: 0.982200\n",
      "Step: 3500, Loss: 796.853577, Accuracy: 0.978000\n",
      "Step: 3600, Loss: 774.449219, Accuracy: 0.979300\n",
      "Step: 3700, Loss: 744.515991, Accuracy: 0.980800\n",
      "Step: 3800, Loss: 700.188965, Accuracy: 0.982700\n",
      "Step: 3900, Loss: 733.451233, Accuracy: 0.981300\n",
      "Step: 4000, Loss: 752.622314, Accuracy: 0.980500\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(4000):\n",
    "    i += 1\n",
    "    batch_xs, batch_ts = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, t: batch_ts})\n",
    "    if i % 100 == 0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy],\n",
    "            feed_dict={x:mnist.test.images, t:mnist.test.labels})\n",
    "        print ('Step: %d, Loss: %f, Accuracy: %f'\n",
    "               % (i, loss_val, acc_val))\n",
    "        # 現在のディレクトリにモデル用のディレクトリをつくらない場合は，今のスクリプトがあるところまでのpath(今だと pwd)を指定してやる必要がある. \n",
    "        # ディレクトリを作ってたる場合には directory/file だけでOK directory がない場合は作成してくれる\n",
    "        saver.save(sess, 'tensorflow/mdc_session', global_step=i)  # ディレクトリを使う場合\n",
    "        #　saver.save(sess, str(abs_root / 'mdc_session', global_step=i)  # 与えるファイルパスは './mdc_session'でもOK?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[MDC-08]** セッション情報を保存したファイルが生成されていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mdc_session*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm mdc_session*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd+'/mdc_session'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Lambda, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import TruncatedNormal, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20160703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "convolution (Conv2D)         (None, 28, 28, 16)        400       \n",
      "_________________________________________________________________\n",
      "pool (MaxPooling2D)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "fully-connected (Dense)      (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,222,938\n",
      "Trainable params: 3,222,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_filters, num_units =16, 1024\n",
    "num_units1 = 14*14*num_filters\n",
    "num_units2 = num_units\n",
    "\n",
    "with K.name_scope('CNN'):\n",
    "    model.add(Conv2D(filters=num_filters, kernel_size=5,\n",
    "                     padding=\"same\",\n",
    "                     data_format=\"channels_last\",\n",
    "                     use_bias=False,\n",
    "                     input_shape=(28, 28, 1),\n",
    "                    kernel_initializer=TruncatedNormal(stddev=0.1),\n",
    "                    name='convolution'\n",
    "                    ))\n",
    "\n",
    "    with K.name_scope('pooling'): # TensorFlowのname_scopeが使える． 色々とTensorFlowと変換性がある\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           padding=\"same\", \n",
    "                           data_format=\"channels_last\",\n",
    "                            name='pool'))\n",
    "        model.add(Flatten())  #  入力を平滑化する．バッチサイズに影響されない．\n",
    "\n",
    "    model.add(Dense(units=num_units2, activation='relu', name='fully-connected'))\n",
    "    model.add(Dense(units=10, activation='softmax', name='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboad = TensorBoard(log_dir='/tmp/mnist_df_logs', histogram_freq=1)  # histogram_freq=50で 50 epochごとに記録することになる\n",
    "earlystopping = EarlyStopping(monitor='val_loss',  patience=5, verbose=1)\n",
    "\n",
    "# ModelCheckpointでエポックごとにセッションを保存 : 詳しくは「詳解ディープラーニング  p300~」\n",
    "checkpoint = ModelCheckpoint(\n",
    "                            filepath=str(abs_root / 'keras_session/model_{epoch:02d}_vloss{val_loss:.3f}.hdf5'),\n",
    "                            save_best_only=True)  #  save_best_only=True　だと そのとき最もよかった結果を上書きしないで済む?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(lr=0.0005),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, t_train = mnist.train.images,mnist.train.labels\n",
    "x_train.shape, t_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, t_test = mnist.test.images,mnist.test.labels\n",
    "x_test.shape, t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir keras_session  # Kerasの場合はディレクトリを作らないといけない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "55000/55000 [==============================] - 59s 1ms/step - loss: 0.2179 - acc: 0.9364 - val_loss: 0.0925 - val_acc: 0.9729\n",
      "Epoch 2/7\n",
      "55000/55000 [==============================] - 58s 1ms/step - loss: 0.0679 - acc: 0.9801 - val_loss: 0.0622 - val_acc: 0.9796\n",
      "Epoch 3/7\n",
      "55000/55000 [==============================] - 58s 1ms/step - loss: 0.0389 - acc: 0.9883 - val_loss: 0.0597 - val_acc: 0.9808\n",
      "Epoch 4/7\n",
      "55000/55000 [==============================] - 58s 1ms/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0484 - val_acc: 0.9846\n",
      "Epoch 5/7\n",
      "55000/55000 [==============================] - 58s 1ms/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0558 - val_acc: 0.9834\n",
      "Epoch 6/7\n",
      "55000/55000 [==============================] - 58s 1ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0471 - val_acc: 0.9859\n",
      "Epoch 7/7\n",
      "55000/55000 [==============================] - 60s 1ms/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0616 - val_acc: 0.9814\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "x_train = x_train.reshape([-1,28,28,1])\n",
    "x_test = x_test.reshape([-1,28,28,1])\n",
    "\n",
    "hist = model.fit(x_train, t_train, batch_size=100,\n",
    "                         epochs=7,\n",
    "                         validation_data=(x_test, t_test),\n",
    "                         callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
